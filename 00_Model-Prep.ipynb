{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24925fa-132f-4d3b-aa26-5980f04e5cfc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## HuggingFace Model Conversion to ONNX and some adjustments to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7e7d4-429f-49d0-87ee-8256d045ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit manConfig.json file FIRST to set variables BEFORE running any commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556ef2cc-1ea5-4207-ad2b-6d6c2a7fcc4d",
   "metadata": {},
   "source": [
    "## Model preparation (fixing dynamic dims, fixing versions for compatibility, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e11a55-3b9b-4e06-a213-49ceae6275e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0) Imports ---\n",
    "import os, sys, json, glob, subprocess\n",
    "import getpass\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from onnxruntime.tools.onnx_model_utils import make_dim_param_fixed\n",
    "\n",
    "import teradataml as tdml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddcefc8-9320-4cc4-89d5-30c3c51f7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Load config ---\n",
    "cfg_path = \"./manConfig.json\"\n",
    "with open(cfg_path, \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "db = cfg[\"db\"]\n",
    "log = cfg[\"log\"]\n",
    "model_cfg = cfg[\"model\"]\n",
    "\n",
    "td_host = db[\"hostName\"]\n",
    "u_name  = db[\"userName\"]\n",
    "db_name = db[\"dbName\"]\n",
    "db_logmech = db.get(\"logmech\", \"LDAP\")           # LDAP by default\n",
    "table_prefix = db.get(\"tablePrefix\", \"misc\")\n",
    "model_table  = db.get(\"modelTable\", \"embeddings_models\")\n",
    "tok_table    = db.get(\"tokenizerTable\", \"embeddings_tokenizers\")\n",
    "\n",
    "model_id     = model_cfg[\"modelNameShort\"]\n",
    "model_name   = model_cfg[\"hubModelId\"]\n",
    "out_dir      = model_cfg[\"outputDir\"]\n",
    "opset        = int(model_cfg.get(\"opset\", 16))\n",
    "trust_remote = bool(model_cfg.get(\"trustRemoteCode\", True))\n",
    "onnx_files   = model_cfg.get(\"onnxFiles\", \"model.onnx\")   # string | list | glob(s)\n",
    "apply_fixes  = bool(model_cfg.get(\"applyPostFixes\", True))\n",
    "bs = int(model_cfg.get(\"fixedBatchSize\", 1))\n",
    "sl = int(model_cfg.get(\"fixedSequenceLength\", 512))\n",
    "ed = int(model_cfg.get(\"fixedEmbeddingDim\", 384))\n",
    "\n",
    "debug = bool(log.get(\"debug\", False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227d5956-e9d4-4487-8b3b-26a016b159bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exec] optimum-cli export onnx -m BAAI/bge-small-en-v1.5 bge-small-en-v1.5-onnx --opset 16 --trust-remote-code\n",
      "Opset 16 is lower than the recommended minimum opset (18) to export transformer. The ONNX export may fail or the exported model may be suboptimal.\n",
      "C:\\Users\\bd185021\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n",
      "\n",
      "[warn] Success message not detected, but process returned 0. Proceeding...\n"
     ]
    }
   ],
   "source": [
    "# --- 2) Export the model with Optimum CLI ---\n",
    "cli_cmd = [\n",
    "    \"optimum-cli\", \"export\", \"onnx\",\n",
    "    \"-m\", model_name,\n",
    "    out_dir,\n",
    "    \"--opset\", str(opset)\n",
    "]\n",
    "if trust_remote:\n",
    "    cli_cmd.append(\"--trust-remote-code\")\n",
    "\n",
    "print(f\"[exec] {' '.join(cli_cmd)}\")\n",
    "res = subprocess.run(cli_cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "print(res.stdout)\n",
    "if res.returncode != 0:\n",
    "    raise RuntimeError(\"Optimum export failed. See logs above.\")\n",
    "# (Optional) sanity check for success message:\n",
    "if \"exported model was saved at\" not in res.stdout.lower():\n",
    "    print(\"[warn] Success message not detected, but process returned 0. Proceeding...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d33491-df4c-4015-ac5d-6125b907ca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] ONNX files to process:\n",
      "  - bge-small-en-v1.5-onnx\\model.onnx\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Resolve ONNX files to process ---\n",
    "def resolve_onnx_paths(output_dir, spec):\n",
    "    paths = []\n",
    "    candidates = [spec] if isinstance(spec, str) else (spec if isinstance(spec, list) else [\"model.onnx\"])\n",
    "    for c in candidates:\n",
    "        if any(ch in c for ch in [\"*\", \"?\"]):  # glob pattern\n",
    "            matches = glob.glob(os.path.join(output_dir, c))\n",
    "            if not matches:\n",
    "                print(f\"[warn] glob '{c}' did not match any files under {output_dir}\")\n",
    "            paths.extend(matches)\n",
    "        else:\n",
    "            p = os.path.join(output_dir, c)\n",
    "            if not os.path.isfile(p):\n",
    "                print(f\"[warn] file '{c}' not found under {output_dir}\")\n",
    "            else:\n",
    "                paths.append(p)\n",
    "    # de-dupe\n",
    "    dedup = []\n",
    "    seen = set()\n",
    "    for p in paths:\n",
    "        if p not in seen:\n",
    "            dedup.append(p)\n",
    "            seen.add(p)\n",
    "    if not dedup:\n",
    "        raise FileNotFoundError(\"No ONNX files resolved. Check 'onnxFiles' or export output.\")\n",
    "    print(\"[info] ONNX files to process:\")\n",
    "    for p in dedup: print(f\"  - {p}\")\n",
    "    return dedup\n",
    "\n",
    "onnx_paths = resolve_onnx_paths(out_dir, onnx_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30c39961-757f-4269-918b-65717e3668e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Loading ONNX: bge-small-en-v1.5-onnx\\model.onnx\n",
      "[info] Fixing dims for 'model.onnx': batch_size=1, sequence_length=512, embedding_dim=384\n",
      "[info] Removed 'token_embeddings' from outputs.\n",
      "[info] Remaining outputs: ['sentence_embedding']\n",
      "[info] Saving fixed ONNX: bge-small-en-v1.5-onnx\\fixed_model.onnx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 4) Apply IR/opset + dimension fixes, remove token_embeddings ---\n",
    "fixed_paths = []\n",
    "\n",
    "for onnx_path in onnx_paths:\n",
    "    base = os.path.basename(onnx_path)\n",
    "    fixed_path = os.path.join(out_dir, f\"fixed_{base}\")\n",
    "\n",
    "    print(f\"[info] Loading ONNX: {onnx_path}\")\n",
    "    raw_model = onnx.load(onnx_path)\n",
    "\n",
    "    # Set desired opset\n",
    "    op = onnx.OperatorSetIdProto()\n",
    "    op.version = opset\n",
    "\n",
    "    # Align IR/opset explicitly\n",
    "    model_ir = onnx.helper.make_model(\n",
    "        raw_model.graph,\n",
    "        ir_version=8,\n",
    "        opset_imports=[op]\n",
    "    )\n",
    "\n",
    "    # Lock dynamic dims (if symbols present)\n",
    "    print(f\"[info] Fixing dims for '{base}': batch_size={bs}, sequence_length={sl}, embedding_dim={ed}\")\n",
    "    for sym, val in [\n",
    "        (\"batch_size\", bs),\n",
    "        (\"sequence_length\", sl),\n",
    "        (\"Divsentence_embedding_dim_1\", ed),\n",
    "        (\"sentence_embedding_dim_1\", ed),\n",
    "        (\"embedding_dim_1\", ed),\n",
    "    ]:\n",
    "        try:\n",
    "            make_dim_param_fixed(model_ir.graph, sym, val)\n",
    "        except Exception:\n",
    "            # Symbol may not exist in this graph; ignore gracefully.\n",
    "            pass\n",
    "\n",
    "    # Remove token-level outputs safely (reverse iteration)\n",
    "    removed = False\n",
    "    outputs = model_ir.graph.output\n",
    "    for i in reversed(range(len(outputs))):\n",
    "        if outputs[i].name == \"token_embeddings\":\n",
    "            del outputs[i]\n",
    "            removed = True\n",
    "\n",
    "    if removed:\n",
    "        print(\"[info] Removed 'token_embeddings' from outputs.\")\n",
    "    else:\n",
    "        print(\"[info] No 'token_embeddings' output found; nothing to remove.\")\n",
    "\n",
    "    # Optional: print the remaining outputs for sanity\n",
    "    out_names = [o.name for o in model_ir.graph.output]\n",
    "    print(f\"[info] Remaining outputs: {out_names}\")\n",
    "\n",
    "    print(f\"[info] Saving fixed ONNX: {fixed_path}\")\n",
    "    onnx.save(model_ir, fixed_path)\n",
    "    fixed_paths.append(fixed_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df79517-1e4f-420a-b7e3-fbb2bb44009d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Model deployment to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a247124b-2e15-48ae-84f3-1105446e0345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Connecting to Teradata host=192.168.100.20, db=td01, logmech=TD2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Engine(teradatasql://td01:***@192.168.100.20?DATABASE=td01&LOGDATA=%2A%2A%2A&LOGMECH=%2A%2A%2A)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 5) Connect to Teradata ---\n",
    "u_password = \"td01\"  # keep your current approach; replace if you want to prompt or read from secrets\n",
    "if not u_name:\n",
    "    u_name = input(\"User Name: \")\n",
    "if not u_password:\n",
    "    u_password = getpass.getpass(prompt=\"Password: \")\n",
    "\n",
    "print(f\"[info] Connecting to Teradata host={td_host}, db={db_name}, logmech={db_logmech}\")\n",
    "tdml.create_context(host=td_host, username=u_name, password=u_password, database=db_name, logmech=db_logmech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9d126-a4f2-4cd2-b170-78927c93dfb1",
   "metadata": {},
   "source": [
    "## Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ac914-09ef-4ba3-b0de-e03388d865b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Deploying the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ab0f9b-f8a0-4e62-a8f5-78f50ae72135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Saving model file to 'embeddings_models': bge-small-en-v1.5-onnx\\fixed_model.onnx\n",
      "Created the model table 'embeddings_models' as it does not exist.\n",
      "Model is saved.\n",
      "[info] Saving tokenizer to 'embeddings_tokenizers': bge-small-en-v1.5-onnx\\tokenizer.json\n",
      "Created the model table 'embeddings_tokenizers' as it does not exist.\n",
      "Model is saved.\n",
      "[done] Model(s) and tokenizer deployed to Teradata BYOM tables.\n"
     ]
    }
   ],
   "source": [
    "# --- 6) Save model(s) & tokenizer to BYOM tables ---\n",
    "# Model ID uses the HF ID for clarity; feel free to change if you prefer a shorter key.\n",
    "# model_id = model_name\n",
    "\n",
    "# Save each fixed ONNX file\n",
    "for p in fixed_paths:\n",
    "    print(f\"[info] Saving model file to '{model_table}': {p}\")\n",
    "    tdml.save_byom(model_id, p, model_table)\n",
    "\n",
    "# Save tokenizer\n",
    "tok_path = os.path.join(out_dir, \"tokenizer.json\")\n",
    "if os.path.isfile(tok_path):\n",
    "    print(f\"[info] Saving tokenizer to '{tok_table}': {tok_path}\")\n",
    "    tdml.save_byom(model_id, tok_path, tok_table)\n",
    "else:\n",
    "    print(f\"[warn] tokenizer.json not found under {out_dir}. If Optimum produced a different tokenizer file, load that instead.\")\n",
    "\n",
    "print(\"[done] Model(s) and tokenizer deployed to Teradata BYOM tables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b824c48-9631-4acf-ae51-81f6e88b13f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdml.remove_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b64c7-39ce-4f06-8324-c8ea74d9d516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
